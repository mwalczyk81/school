{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# Assignment 9\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Matthew Walczyk  \n",
    "**Date:** 10/14/2024  \n",
    "**Modified By:** Matthew Walczyk  \n",
    "**Description:** This program contains my week 6 exercises using pandas and scipy.\n",
    "\n",
    "---\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame from np.csv:\n",
      "          0         1         2         3\n",
      "0  0.374540  0.950714  0.731994  0.598658\n",
      "1  0.156019  0.155995  0.058084  0.866176\n",
      "2  0.601115  0.708073  0.020584  0.969910\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "array_3x4 = np.random.rand(3, 4)\n",
    "\n",
    "# Save the array to a CSV file named np.csv\n",
    "np.savetxt(\"np.csv\", array_3x4, delimiter=\",\")\n",
    "\n",
    "# Create a DataFrame from the file and print the results\n",
    "df_from_np_csv = pd.read_csv(\"np.csv\", header=None)\n",
    "print(\"DataFrame from np.csv:\")\n",
    "print(df_from_np_csv)\n",
    "\n",
    "# Write the DataFrame to a new CSV file\n",
    "df_from_np_csv.to_csv(\"df_from_np.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle size: 365\n"
     ]
    }
   ],
   "source": [
    "array_365x4 = np.random.rand(365, 4)\n",
    "\n",
    "# Store the array in a CSV file and check its size\n",
    "np.savetxt(\"array_365x4.csv\", array_365x4, delimiter=\",\")\n",
    "csv_size = pd.read_csv(\"array_365x4.csv\").shape\n",
    "\n",
    "# Save the array in the NumPy format, load it, and check its shape\n",
    "np.save(\"array_365x4.npy\", array_365x4)\n",
    "loaded_array = np.load(\"array_365x4.npy\")\n",
    "npy_shape = loaded_array.shape\n",
    "\n",
    "# Write the DataFrame to a pickle, retrieve it, and print the size of the pickle\n",
    "df_365x4 = pd.DataFrame(array_365x4)\n",
    "df_365x4.to_pickle(\"df_365x4.pkl\")\n",
    "loaded_pickle = pd.read_pickle(\"df_365x4.pkl\")\n",
    "pickle_size = len(loaded_pickle)\n",
    "print(\"Pickle size:\", pickle_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame from Excel:\n",
      "            0         1         2         3\n",
      "0    0.832443  0.212339  0.181825  0.183405\n",
      "1    0.304242  0.524756  0.431945  0.291229\n",
      "2    0.611853  0.139494  0.292145  0.366362\n",
      "3    0.456070  0.785176  0.199674  0.514234\n",
      "4    0.592415  0.046450  0.607545  0.170524\n",
      "..        ...       ...       ...       ...\n",
      "360  0.868905  0.570610  0.030387  0.930949\n",
      "361  0.689527  0.676513  0.215675  0.658885\n",
      "362  0.393864  0.651233  0.106593  0.657845\n",
      "363  0.999414  0.048212  0.977174  0.406908\n",
      "364  0.870753  0.782385  0.567016  0.738449\n",
      "\n",
      "[365 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df_365x4.to_excel(\"df_365x4.xlsx\", index=False)\n",
    "\n",
    "# Create a DataFrame from the Excel file and print results\n",
    "df_from_excel = pd.read_excel(\"df_365x4.xlsx\")\n",
    "print(\"DataFrame from Excel:\")\n",
    "print(df_from_excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country value before change: Netherlands\n",
      "Country value after change: MyCountry\n"
     ]
    }
   ],
   "source": [
    "json_str = '''{\n",
    "    \"country\": \"Netherlands\", \"dma_code\": \"0\", \"timezone\": \"Europe/Amsterdam\",\n",
    "    \"area_code\": \"0\", \"ip\": \"46.19.37.108\", \"asn\": \"AS196752\", \n",
    "    \"continent_code\": \"EU\", \"isp\": \"Tilaa V.O.F.\", \"longitude\": 5.75, \n",
    "    \"latitude\": 52.5, \"country_code\": \"NL\", \"country_code3\": \"NLD\"\n",
    "}'''\n",
    "\n",
    "parsed_json = json.loads(json_str)\n",
    "print(\"Country value before change:\", parsed_json['country'])\n",
    "\n",
    "# Overwrite the value for Netherlands with a new value\n",
    "parsed_json['country'] = 'MyCountry'\n",
    "print(\"Country value after change:\", parsed_json['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series from JSON:\n",
      "country                  MyCountry\n",
      "dma_code                         0\n",
      "timezone          Europe/Amsterdam\n",
      "area_code                        0\n",
      "ip                    46.19.37.108\n",
      "asn                       AS196752\n",
      "continent_code                  EU\n",
      "isp                   Tilaa V.O.F.\n",
      "longitude                     5.75\n",
      "latitude                      52.5\n",
      "country_code                    NL\n",
      "country_code3                  NLD\n",
      "dtype: object\n",
      "JSON string from modified Series:\n",
      "{\"country\":\"NewCountry\",\"dma_code\":\"0\",\"timezone\":\"Europe\\/Amsterdam\",\"area_code\":\"0\",\"ip\":\"46.19.37.108\",\"asn\":\"AS196752\",\"continent_code\":\"EU\",\"isp\":\"Tilaa V.O.F.\",\"longitude\":5.75,\"latitude\":52.5,\"country_code\":\"NL\",\"country_code3\":\"NLD\"}\n"
     ]
    }
   ],
   "source": [
    "series_from_json = pd.Series(parsed_json)\n",
    "print(\"Series from JSON:\")\n",
    "print(series_from_json)\n",
    "\n",
    "# Change the country value again and convert the Series to a JSON string\n",
    "series_from_json['country'] = 'NewCountry'\n",
    "json_from_series = series_from_json.to_json()\n",
    "print(\"JSON string from modified Series:\")\n",
    "print(json_from_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First div \n",
      " <div class=\"tile\">\n",
      "<h4>Development</h4>\n",
      "     0.10.1 - July 2014<br/>\n",
      "</div>\n",
      "First div class ['tile']\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(open('C:/Users/fclplb8/Source/repos/Python-Data-Analysis/Chapter05/loremIpsum.html'))\n",
    "\n",
    "print(\"First div \\n\", soup.div)\n",
    "\n",
    "print(\"First div class\", soup.div['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First dfn text Quare attende, quaeso.\n"
     ]
    }
   ],
   "source": [
    "print(\"First dfn text\", soup.dl.dt.dfn.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link text loripsum.net URL http://loripsum.net/\n",
      "Link text Poterat autem inpune; URL http://loripsum.net/\n",
      "Link text Is es profecto tu. URL http://loripsum.net/\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('a'):\n",
    "    print(\"Link text\", link.string, \"URL\", link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['\\n', <h4>Development</h4>, '\\n     0.10.1 - July 2014', <br/>, '\\n']\n",
      "1 ['\\n', <h4>Official Release</h4>, '\\n     0.10.0 June 2014', <br/>, '\\n']\n",
      "2 ['\\n', <h4>Previous Release</h4>, '\\n     0.09.1 June 2013', <br/>, '\\n']\n"
     ]
    }
   ],
   "source": [
    "for i, div in enumerate(soup('div')):\n",
    "    print(i, div.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Official Version 0.10.0 June 2014\n"
     ]
    }
   ],
   "source": [
    "official_div = soup.find('div', id='official')\n",
    "\n",
    "# Book is wrong or outdated there is no [0] on the div\n",
    "print(\"Official Version\", official_div.contents[2].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # elements with class 3\n"
     ]
    }
   ],
   "source": [
    "print(\" # elements with class\", len(soup.find_all(class_=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tile classes 2\n"
     ]
    }
   ],
   "source": [
    "tile_class = soup.find_all(\"div\",class_='tile')\n",
    "print(\"# Tile classes\", len(tile_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Divs with class containing tile 3\n"
     ]
    }
   ],
   "source": [
    "print(\"# Divs with class containing tile\", len(soup.find_all(\"div\", class_=re.compile(\"tile\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CSS selector\n",
      " [<div class=\"notile\">\n",
      "<h4>Previous Release</h4>\n",
      "     0.09.1 June 2013<br/>\n",
      "</div>]\n"
     ]
    }
   ],
   "source": [
    "print(\"Using CSS selector\\n\", soup.select('div.notile'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting ordered list list itmes\n",
      " [<li>Cur id non ita fit?</li>, <li>In qua si nihil est praeter rationem, sit in una virtute finis bonorum;</li>]\n"
     ]
    }
   ],
   "source": [
    "print(\"Selecting ordered list list itmes\\n\", soup.select('ol > li')[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second list item in ordered list [<li>In qua si nihil est praeter rationem, sit in una virtute finis bonorum;</li>]\n"
     ]
    }
   ],
   "source": [
    "print(\"Second list item in ordered list\", soup.select(\"ol>li:nth-of-type(2)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for text string ['\\n     0.10.1 - July 2014', '\\n     0.10.0 June 2014']\n"
     ]
    }
   ],
   "source": [
    "print(\"Searching for text string\", soup.find_all(string=re.compile(\"2014\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
