{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# Assignment 6\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Matthew Walczyk  \n",
    "**Date:** 9/30/2024  \n",
    "**Modified By:** Matthew Walczyk  \n",
    "**Description:** This program contains my week 6 exercises using pandas.\n",
    "\n",
    "---\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mag magType           time                               place  tsunami  \\\n",
      "227 5.20      mb  1539389603790             15km WSW of Pisco, Peru        0   \n",
      "229 4.90      mb  1539389546300        193km N of Qulansiyah, Yemen        0   \n",
      "248 4.90      mb  1539382925190  151km S of Severo-Kuril'sk, Russia        0   \n",
      "258 5.10      mb  1539380306940       236km NNW of Kuril'sk, Russia        0   \n",
      "391 5.10      mb  1539337221080             Pacific-Antarctic Ridge        0   \n",
      "\n",
      "                parsed_place  \n",
      "227                     Peru  \n",
      "229                    Yemen  \n",
      "248                   Russia  \n",
      "258                   Russia  \n",
      "391  Pacific-Antarctic Ridge  \n"
     ]
    }
   ],
   "source": [
    "earthquakes = pd.read_csv('https://raw.githubusercontent.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/refs/heads/master/ch_04/exercises/earthquakes.csv')\n",
    "\n",
    "filtered_quakes = earthquakes[(earthquakes['magType'] == 'mb') & (earthquakes['mag'] >= 4.9)]\n",
    "\n",
    "print(filtered_quakes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "magnitude_bin\n",
      "[-1, 0)     446\n",
      "[0, 1)     2072\n",
      "[1, 2)     3126\n",
      "[2, 3)      985\n",
      "[3, 4)      153\n",
      "[4, 5)        6\n",
      "[5, 6)        2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# I made a copy because I was getting a warning about setting a value on a copy of a slice from a DataFrame\n",
    "ml_quakes = earthquakes[earthquakes['magType'] == 'ml'].copy()\n",
    "\n",
    "bins = range(int(ml_quakes['mag'].min()), int(ml_quakes['mag'].max()) + 2)  # Think this needs to be +2 to include the max value\n",
    "\n",
    "ml_quakes.loc[:, 'magnitude_bin'] = pd.cut(ml_quakes['mag'], bins=bins, right=False)\n",
    "\n",
    "magnitude_counts = ml_quakes['magnitude_bin'].value_counts().sort_index()\n",
    "\n",
    "print(magnitude_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open             659.20\n",
      "high            2050.50\n",
      "low               36.65\n",
      "close            658.60\n",
      "volume   45832459300.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "faang = pd.read_csv('https://raw.githubusercontent.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/refs/heads/master/ch_04/exercises/faang.csv')\n",
    "\n",
    "aggregations = {\n",
    "    'open': 'mean',\n",
    "    'high': 'max',\n",
    "    'low': 'min',\n",
    "    'close': 'mean',\n",
    "    'volume': 'sum'\n",
    "}\n",
    "\n",
    "# Doing this because I did not want to see scientific notation\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "print(faang.agg(aggregations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "magType   mb  mb_lg   md   mh   ml  ms_20   mw  mwb  mwr  mww\n",
      "tsunami                                                      \n",
      "0       5.60   3.50 4.11 1.10 4.20    NaN 3.83 5.80 4.80 6.00\n",
      "1       6.10    NaN  NaN  NaN 5.10   5.70 4.41  NaN  NaN 7.50\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(\n",
    "    earthquakes['tsunami'], \n",
    "    earthquakes['magType'], \n",
    "    values=earthquakes['mag'], \n",
    "    aggfunc='max'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       open   high    low  close        volume\n",
      "59    43.09  45.88  37.56  43.07 9051611600.00\n",
      "60    43.08  45.88  37.56  43.05 9102982000.00\n",
      "61    43.05  45.88  37.56  43.02 9135257600.00\n",
      "62    43.03  45.88  37.56  43.01 9166631200.00\n",
      "63    43.00  45.88  37.56  42.99 9210413200.00\n",
      "...     ...    ...    ...    ...           ...\n",
      "1250 306.02 386.80 233.68 303.24  811001500.00\n",
      "1251 303.60 386.80 231.23 301.23  818289300.00\n",
      "1252 301.50 386.80 231.23 299.13  822147900.00\n",
      "1253 299.39 380.93 231.23 297.12  824502000.00\n",
      "1254 297.42 380.00 231.23 295.29  832212300.00\n",
      "\n",
      "[960 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Sorting to make sure the rolling window works\n",
    "faang['date'] = pd.to_datetime(faang['date'])\n",
    "faang = faang.sort_values(['ticker', 'date'])\n",
    "\n",
    "# Not sure if we were supposed to drop the NaNs or not, but I did because it looked better\n",
    "print(faang.groupby('ticker').rolling(window=60, on='date').agg({\n",
    "    'open': 'mean',\n",
    "    'high': 'max',\n",
    "    'low': 'min',\n",
    "    'close': 'mean',\n",
    "    'volume': 'sum'\n",
    "}).reset_index(drop=True).dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         close    high     low    open       volume\n",
      "ticker                                             \n",
      "AAPL     47.26   47.75   46.80   47.28 136080258.17\n",
      "AMZN   1641.73 1662.84 1619.84 1644.07   5648994.42\n",
      "FB      171.51  173.61  169.30  171.47  27658596.81\n",
      "GOOG   1113.23 1125.78 1101.00 1113.55   1741965.34\n",
      "NFLX    319.29  325.22  313.19  319.62  11469624.70\n"
     ]
    }
   ],
   "source": [
    "print(faang.pivot_table(\n",
    "    index='ticker', \n",
    "    values=['open', 'high', 'low', 'close', 'volume'], \n",
    "    aggfunc='mean'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     open  high   low  close  volume\n",
      "690  2.36  2.39  2.52   2.41   -1.64\n",
      "691  2.21  2.25  2.27   2.17   -0.87\n",
      "692  2.09  2.08  2.16   2.04   -0.93\n",
      "693  1.86  1.83  1.80   1.74   -0.13\n",
      "694  1.66  1.64  1.57   1.60   -0.30\n",
      "..    ...   ...   ...    ...     ...\n",
      "748 -2.20 -2.18 -2.21  -2.24   -0.14\n",
      "749 -2.04 -1.62 -1.83  -1.35    1.13\n",
      "750 -1.47 -1.65 -1.64  -1.42    0.86\n",
      "751 -1.34 -1.34 -1.24  -1.30    0.50\n",
      "752 -1.09 -1.28 -0.98  -1.13   -0.25\n",
      "\n",
      "[63 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "amzn_q4_2018 = faang[(faang['ticker'] == 'AMZN') & \n",
    "                     (faang['date'] >= '2018-10-01') & \n",
    "                     (faang['date'] <= '2018-12-31')]\n",
    "\n",
    "amzn_q4_2018_numeric = amzn_q4_2018[['open', 'high', 'low', 'close', 'volume']]\n",
    "\n",
    "# Using the zscore function from scipy.stats\n",
    "print(amzn_q4_2018_numeric.apply(zscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ticker       date    high     low    open   close       volume event\n",
      "0      AAPL 2018-01-02   43.08   42.31   42.54   43.06 102223600.00   NaN\n",
      "1      AMZN 2018-01-02 1190.00 1170.51 1172.00 1189.01   2694500.00   NaN\n",
      "2        FB 2018-01-02  181.58  177.55  177.68  181.42  18151900.00   NaN\n",
      "3      GOOG 2018-01-02 1066.94 1045.23 1048.34 1065.00   1237600.00   NaN\n",
      "4      NFLX 2018-01-02  201.65  195.42  196.10  201.07  10966900.00   NaN\n",
      "...     ...        ...     ...     ...     ...     ...          ...   ...\n",
      "1250   AAPL 2018-12-31   39.84   39.12   39.63   39.44 140014000.00   NaN\n",
      "1251   AMZN 2018-12-31 1520.76 1487.00 1510.80 1501.97   6954500.00   NaN\n",
      "1252     FB 2018-12-31  134.64  129.95  134.45  131.09  24625300.00   NaN\n",
      "1253   GOOG 2018-12-31 1052.70 1023.59 1050.96 1035.61   1493300.00   NaN\n",
      "1254   NFLX 2018-12-31  270.10  260.00  260.16  267.66  13508900.00   NaN\n",
      "\n",
      "[1255 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "events_data = {\n",
    "    'ticker': ['FB', 'FB', 'FB'],\n",
    "    'date': ['2018-07-25', '2018-03-19', '2018-03-20'],\n",
    "    'event': [\n",
    "        'Disappointing user growth announced after close.',\n",
    "        'Cambridge Analytica story',\n",
    "        'FTC investigation'\n",
    "    ]\n",
    "}\n",
    "\n",
    "events_df = pd.DataFrame(events_data)\n",
    "\n",
    "# Convert 'date' column to datetime\n",
    "events_df['date'] = pd.to_datetime(events_df['date'])\n",
    "events_df.set_index(['date', 'ticker'], inplace=True)\n",
    "\n",
    "# Merge it!\n",
    "print(pd.merge(faang, events_df, how='outer', on=['date', 'ticker']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      open  high  low  close  volume\n",
      "251   1.00  1.00 1.00   1.00    1.00\n",
      "252   1.01  1.01 1.02   1.00    1.16\n",
      "253   1.01  1.01 1.02   1.00    0.88\n",
      "254   1.02  1.02 1.02   1.02    0.93\n",
      "255   1.02  1.02 1.03   1.01    0.80\n",
      "...    ...   ...  ...    ...     ...\n",
      "999   1.23  1.24 1.20   1.16    0.87\n",
      "1000  1.19  1.26 1.18   1.26    1.31\n",
      "1001  1.28  1.27 1.23   1.27    1.12\n",
      "1002  1.32  1.30 1.28   1.27    1.00\n",
      "1003  1.33  1.34 1.33   1.33    1.23\n",
      "\n",
      "[1255 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Just making sure the data is in the right order\n",
    "faang = faang.sort_values(['ticker', 'date'])\n",
    "\n",
    "print(faang.groupby('ticker')[['open', 'high', 'low', 'close', 'volume']].transform(lambda x: x / x.iloc[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
